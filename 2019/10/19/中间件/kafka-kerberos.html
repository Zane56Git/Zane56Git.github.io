<hr>
<p>title: kafka之kerberos认证（release）<br>tags: </p>
<ul>
<li>kafka<br>categories:</li>
<li>中间件<br>toc: true<br>date: 2021-08-03 13:52:25</li>
</ul>
<hr>
<p>在工作中接触kafka很多，但是kafka集成kerberos也是必不可少的，在实际项目中进行kerberos认证还是会有出现很多问题，所以仅以此篇记录kerberos认证相关步骤及问题点，方便以后使用。</p>
<h1 id="kerberos"><a href="#kerberos" class="headerlink" title="kerberos"></a>kerberos</h1><h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><p><strong>Kerberos</strong>是一种计算机网络授权协议，用来在非安全<a href="https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C">网络</a>中，对个人通信以安全的手段进行身份认证。这个词又指<a href="https://baike.baidu.com/item/%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A5%E5%AD%A6%E9%99%A2">麻省理工学院</a>为这个协议开发的一套计算机软件。</p>
<p>Kerberos是一种客户端/服务端架构。</p>
<p>KDC：密钥分发中心（Key distribution Center），由三部分构成：Kerberos数据库、认证服务（Authentication service，AS）和票据授予服务（ticket-granting service，TGS）</p>
<p>principal：主体，Kerberos中的身份标识称为主体。</p>
<p>realm：域，确定了管理边界，所有主体均属于特定的Kerberos域。</p>
<p>主体和域的信息存储在Kerberos数据库中。</p>
<p>TGT：票据授予票据，AS认证成功后授予用户的一种特殊票据。</p>
<ul>
<li><em>关于keytab文件</em></li>
</ul>
<p>所有Kerberos服务器都需要一个keytab文件授权链接到KDC，默认文件名为：krb5.keytab。该文件是主机key的本地拷贝。</p>
<p>要为主机生成keytab文件，主机必须在Kerberos数据库中拥有一个principal。</p>
<h1 id="Kerberos安装（偏运维）"><a href="#Kerberos安装（偏运维）" class="headerlink" title="Kerberos安装（偏运维）"></a>Kerberos安装（偏运维）</h1><p>安装Kerberos KDC服务端</p>
<p>Kerberos属于主从结构，我们这里使用一台KDC服务器，3个客户端，另外集群中需要有一台服务器作为时间同步服务器安装NTP服务，Kerberos对NTP服务有依赖，必须进行安装。</p>
<p>操作步骤：</p>
<pre><code>1. 编辑/etc/hosts文件保证主机名和IP地址正确对应

2. 安装KDC

3. 配置kdc.conf文件

4. 配置kadm5.acl文件

5. 配置krb5.conf文件

6. 创建Kerberos数据库

7. 测试Kerberos数据库

8. 启动KDC服务

9. 建立keytab文件

10. 启动kadmind服务
</code></pre>
<p>参考&amp;感谢：<a href="https://blog.csdn.net/weixin_46474921/article/details/123515813">https://blog.csdn.net/weixin_46474921/article/details/123515813</a></p>
<h1 id="Kerberos基本使用"><a href="#Kerberos基本使用" class="headerlink" title="Kerberos基本使用"></a><a href="https://www.cnblogs.com/wind-man/p/14143882.html">Kerberos基本使用</a></h1><pre><code class="shell">创建用户

kadmin.local

addprinc confluent@BIGDATA.COM

或

kadmin.local -q &quot;addprinc confluent@BIGDATA.COM&quot;

 

导出keytab文件

kadmin.local

xst -k /etc/security/keytabs/confluent.keytab confluent@BIGDATA.COM

xst -k /etc/security/keytabs/confluent.keytab -norandkey confluent@BIGDATA.COM

或者

kadmin.local -q &quot;xst -k /etc/security/keytabs/confluent.keytab confluent@BIGDATA.COM&quot;

kadmin.local -q &quot; xst -k /etc/security/keytabs/confluent.keytab -norandkey confluent@BIGDATA.COM&quot;


使用

kinit -kt /etc/security/keytabs/confluent.keytab  confluent@BIGDATA.COM


查看

klist
</code></pre>
<h1 id="Kerberos协议的组成角色"><a href="#Kerberos协议的组成角色" class="headerlink" title="Kerberos协议的组成角色"></a>Kerberos协议的组成角色</h1><p>在古希腊神话故事中，kerberos是一只具有三颗头颅的地狱恶犬，他守护在地狱之外，能够识别所有经此路过的亡灵，防止活着的入侵者闯入地狱。而真正的kerberos协议中也存在三个角色，分别是</p>
<ul>
<li><strong>客户端（client）</strong></li>
<li><strong>服务端（Server）</strong></li>
<li><strong>密钥分发中心（Key Distribution Center，KDC）</strong>，而密钥分发中心一般又分为<strong>AS（Authentication Server）</strong>、<strong>TGS（Ticket Granting Ticket）</strong></li>
</ul>
<h1 id="kerberos的认证原理"><a href="#kerberos的认证原理" class="headerlink" title="kerberos的认证原理"></a>kerberos的认证原理</h1><h1 id="客户端认证实际步骤"><a href="#客户端认证实际步骤" class="headerlink" title="客户端认证实际步骤"></a>客户端认证实际步骤</h1><p>以下操作前提需要先了解kafka在非Kerberos认证环境下的相关生产及消费的相关命令操作；</p>
<p>操作环境：liunx，kafka客户端</p>
<p>首先将认证文件放在规范的文件目录，例如：/opt/third/kafka/keytab 目录</p>
<ol>
<li>创建一个jaas.conf</li>
</ol>
<pre><code class="sh"># 创建配置文件（主要前提会用到kafka.keytab文件，需先生成，例如文件路径：/opt/third/kafka/keytab/kafka.keytab）
cd /opt/third/kafka/keytab/
vi jaas.conf
KafkaClient {
   com.sun.security.auth.module.Krb5LoginModule required
   useKeyTab=true
   keyTab=&quot;/opt/third/kafka/keytab/kafka.keytab&quot;    # keytab    文件路径，如果是ambari安装的，那么可以直接使用conf下的jaas.conf文件
   principal=&quot;kafka@HADOOP.COM&quot;;  #认证的主题
};

Client {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=true
  storeKey=true
  keyTab=&quot;/opt/third/kafka/keytab/kafka.keytab&quot;
  principal=&quot;kafka@HADOOP.COM&quot;;
};
</code></pre>
<p>以上步骤其实已经配置好了kerberos相关的配置文件，还需载入到系统环境变量中，注意，如果是root用户配置的，其他用户使用还需进行配置，除非通过该用户进行配置~/.bash_profile才行</p>
<pre><code class="shell">#配置KAFKA_OPTS环境
export KAFKA_OPTS=&quot;-Djava.security.auth.login.config=/opt/third/kafka/keytab/jaas.conf&quot;
</code></pre>
<ol start="2">
<li><p>生产者认证配置</p>
<p>创建个配置文件(如producer.properties)，当然也可以配置在{KAFAK_HOME}/conf/producer.properties文件最后面，用于生产主题时指定的一些配置，如下：</p>
</li>
</ol>
<pre><code class="shell">security.protocol=SASL_PLAINTEXT
sasl.mechanism=GSSAPI
sasl.kerberos.service.name=kafka #这个指定kerberos的域名，不是主机的ip地址
</code></pre>
<ol start="3">
<li>消费认证配置</li>
</ol>
<p>创建个配置文件(如consumer.properties)，当然也可以配置在{KAFAK_HOME}/conf/consumer.properties文件最后面，用于消费主题时指定的一些配置，如下：</p>
<pre><code class="shell">security.protocol=SASL_PLAINTEXT
sasl.mechanism=GSSAPI
sasl.kerberos.service.name=kafka #这个指定kerberos的域名，不是主机的ip地址
</code></pre>
<ol start="4">
<li>kafka修改安装目录下<code>config/server.properties</code>配置</li>
</ol>
<pre><code class="shell">advertised.listeners=SASL_PLAINTEXT://IP:9092
listeners=SASL_PLAINTEXT://IP:9092
security.inter.broker.protocol=SASL_PLAINTEXT
sasl.mechanism.inter.broker.protocol=GSSAPI
sasl.enabled.mechanisms=GSSAPI
sasl.kerberos.service.name=kafka   
</code></pre>
<ol start="4">
<li>开始使用</li>
</ol>
<pre><code class="shell"># 创建topic
sh /opt/third/kafka/bin/kafka-topics.sh --create --zookeeper emr-node1:2181,emr-node2:2181,emr-node3:2181 --replication-factor 3 --partitions 1 --topic first_topic

# 生产
sh /opt/third/kafka/bin/kafka-console-producer.sh --broker-list 192.168.0.85:9092,192.168.0.100:9092,192.168.0.204:9092 --topic first_topic --producer.config /opt/third/kafka/config/producer.properties

# 消费
sh /opt/third/kafka/bin/kafka-console-consumer.sh --topic first_topic --from-beginning --bootstrap-server 192.168.0.85:9092,192.168.0.100:9092,192.168.0.204:9092 --consumer.config /opt/third/kafka/config/consumer.properties 
</code></pre>
<p>第四步是kafka从topic创建、生产数据到消费数据全过程，这里每一步都会有日志输出，如果没有，说明消费可能已被消费，或者是消费者和生产者监听的topic不一致。</p>
<p>实际遇到的问题</p>
<p>（实际遇见的问题，由于两套kafka公用一个zk，生成的broker不一致，导致生产的数据无法被消费，这样的问题场景给开发人员用户造成很大的排出难点，会误以为是认证配置问题）</p>
<p>排查步骤:</p>
<pre><code class="shell">#查看zookeeper中维护的brokerId
sh /opt/third/kafka/bin/kafka-topics.sh --describe --zookeeper emr-node1:2181,emr-node2:2181,emr-node3:2181 --topic first
#查看kafka中topic对应的brokerId
sh /opt/third/kafka/bin/kafka-consumer-groups.sh  --bootstrap-server 192.168.0.85:9092,192.168.0.100:9092,192.168.0.204:9092 --list
</code></pre>
<p>排查发现topic对应的brokerId和zookeeper中维护的brokerId不一致，通过修改zookeeper的节点目录，删除zk维护节点数据（可能有权限问题），或者重装zookeeper可以解决该问题，主要原因是两个kafka连了同一个zk的/目录作为root目录数据有些冲突。所以换个root目录可以的（这个问题排查至少花费了3天时间。。。）</p>
<h1 id="springboot集成Kerberos认证"><a href="#springboot集成Kerberos认证" class="headerlink" title="springboot集成Kerberos认证"></a>springboot集成Kerberos认证</h1><p>其实Kerberos认证并没有想象的那么复杂，理清所需的认证文件及引入步骤就好了，其实springboot引入主要通过System.setProperty()设置环境属性。</p>
<p>创建kafka-client-jaas.conf、krb5.conf，配置文件中会用到kafka.keytab密钥文件。</p>
<pre><code class="sh">KafkaServer {
   com.sun.security.auth.module.Krb5LoginModule required
   useKeyTab=true
   keyTab=&quot;/opt/test/kafka/config/kerveros/kafka.keytab&quot;
   storeKey=true
   useTicketCache=false
   serviceName=kafka
   principal=&quot;kafka@HADOOP.COM&quot;;
};



KafkaClient {
   com.sun.security.auth.module.Krb5LoginModule required
   useKeyTab=true
   keyTab=&quot;/opt/test/kafka/config/kerveros/kafka.keytab&quot;
   storeKey=true
   useTicketCache=false
   serviceName=kafka
   principal=&quot;kafka@HADOOP.COM&quot;;
   username = &quot;user_abcd@GTMC.COM&quot;
   password = &quot;user_abcd123$&quot;;
};


Client {
        com.sun.security.auth.module.Krb5LoginModule required
        useKeyTab=true
        keyTab=&quot;/opt/test/kafka/config/kerveros/kafka.keytab&quot;
        storeKey=true
        useTicketCache=false
        principal=&quot;kafka@HADOOP.COM&quot;
       serviceName=kafka;
};
</code></pre>
<pre><code class="sh">
[libdefaults]
  renew_lifetime = 7d
  forwardable = true
  default_realm = HADOOP.COM
  ticket_lifetime = 24h
  dns_lookup_realm = false
  dns_lookup_kdc = false
  default_ccache_name = /tmp/krb5cc_%{uid}
  #default_tgs_enctypes = aes des3-cbc-sha1 rc4 des-cbc-md5
  #default_tkt_enctypes = aes des3-cbc-sha1 rc4 des-cbc-md5

[logging]
  default = FILE:/var/log/krb5kdc.log
  admin_server = FILE:/var/log/kadmind.log
  kdc = FILE:/var/log/krb5kdc.log

[realms]
  HADOOP.COM = {
    admin_server = 192.168.10.36
    kdc = 192.168.10.36
  }
</code></pre>
<h1 id="linux环境变量配置的6种方法"><a href="#linux环境变量配置的6种方法" class="headerlink" title="linux环境变量配置的6种方法"></a>linux<a href="https://so.csdn.net/so/search?q=%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F&spm=1001.2101.3001.7020">环境变量</a>配置的6种方法</h1><h3 id="Linux读取环境变量"><a href="#Linux读取环境变量" class="headerlink" title="Linux读取环境变量"></a>Linux读取环境变量</h3><ul>
<li><code>export</code>命令显示当前系统定义的所有环境变量</li>
<li><code>echo $PATH</code>命令输出当前的<code>PATH</code>环境变量的值</li>
</ul>
<p>参考&amp;感谢，待迁移</p>
<p><a href="https://blog.csdn.net/shaoming314/article/details/123973828">https://blog.csdn.net/shaoming314/article/details/123973828</a></p>
